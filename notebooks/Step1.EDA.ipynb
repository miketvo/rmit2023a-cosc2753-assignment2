{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1. Exploratory Data Analysis\n",
    "\n",
    "---\n",
    "\n",
    "In this step, we are exploring our dataset by loading it using our custom `dataset.load()` function. The resulting dataframe consists of the following columns:\n",
    "\n",
    "- **ImgPath**: Path to the image.\n",
    "- **FileType**: The extension of the image file.\n",
    "- **Width**: The width (in pixels) of the image.\n",
    "- **Height**: The height (in pixels) of the image.\n",
    "- **Ratio**: The aspect ratio of the image. Calculated by taking its Width divided by its Height.\n",
    "- **Mode**: The mode of the image. Possible values: [Pillow docs](https://pillow.readthedocs.io/en/latest/handbook/concepts.html#concept-modes).\n",
    "- **Bands**: A string containing all bands of this image, separated by a space character. Read more: [bands](https://pillow.readthedocs.io/en/latest/handbook/concepts.html#bands). Closely related to Mode.\n",
    "- **Transparency**: Whether this image has transparency.\n",
    "- **Animated**: Whether this image has more than one frame.\n",
    "- **Class**: Type of flower in the image. Can be either one of our 8 flower types. **<span style=\"color:red\">TARGET COLUMN</span>**\n",
    "\n",
    "To detect duplicate images, we are comparing the `str` hash of each image calculated using the [imagehash](https://pypi.org/project/ImageHash/) library.\n",
    "\n",
    "For an overview of the dataset, we are focusing on analyzing the following columns:\n",
    "\n",
    "1. **FileType:** We are observing this to see how many different file formats there are in our dataset. These would need to be converted into a single format during data cleaning.\n",
    "2. **Ratio:** From this, we will pick out the most common ratio for our images to be cropped into during data processing.\n",
    "3. **Mode:** Related to transparency: There are only a few modes that support alpha channel necessary for transparency in an image.\n",
    "4. **Transparency:** Machine learning algorithms does not play well with transparent images. We will need to process these.\n",
    "5. **Animated:** Machine learning algorithms cannot process animated images (images with more than 1 frame). If we have such image in our dataset, we need to isolate and extract their individual frames.\n",
    "6. **Class:** We are observing if our dataset is balanced or not, and if this column has the correct format for our Machine Learning models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports and environmental setups\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import imagehash\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Custom utils functions\n",
    "from utils import dataset\n",
    "from utils.visualization import data_countplot\n",
    "from utils.visualization import data_histplot\n",
    "from utils.visualization import data_plot_16samples\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset\n",
    "\n",
    "Using our custom `dataset.load()` function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_raw = dataset.load('../data/raw')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_raw.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_raw.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_raw.sample(n=42, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_plot_16samples(df_raw, to_file='images/EDA-RawDataset-16Samples.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1. Duplicated Images\n",
    "\n",
    "Method: Comparing `imagehash.average_hash()` of each image. Average Hash (aHash) is chosen over other hashing algorithms such as pHash, dHash, wHash... because it is the most computationally efficient while still providing a good result to accurately detect image duplication."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_hashes = {}\n",
    "duplicates_count = 0\n",
    "for i, row in df_raw.iterrows():\n",
    "    with Image.open(f'../data/raw/{row[\"ImgPath\"]}') as im:\n",
    "        image_hash = imagehash.average_hash(im, hash_size=8)\n",
    "        if image_hash in image_hashes:\n",
    "            image_hashes[image_hash].append(row[\"ImgPath\"])\n",
    "            duplicates_count += 1\n",
    "        else:\n",
    "            image_hashes[image_hash] = [row[\"ImgPath\"]]\n",
    "\n",
    "duplicated_image_hashes = {hash_val: paths for hash_val, paths in image_hashes.items() if len(paths) > 1}  # Remove hashes with a single path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Number of duplicated images: {duplicates_count}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Duplication Detection Accuracy:**\n",
    "\n",
    "We are looking at three sample duplications from `duplicated_image_hashes` to check if they are indeed duplications or not:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_indices = [0, len(duplicated_image_hashes.values()) // 2, len(duplicated_image_hashes.values()) - 1]\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(12, 12))\n",
    "\n",
    "for iteration, sample_index in enumerate(sample_indices):\n",
    "    paths = list(duplicated_image_hashes.values())[sample_index]\n",
    "    for i, path in enumerate(paths):\n",
    "        if i >= 2:\n",
    "            break\n",
    "\n",
    "        im = Image.open(f'../data/raw/{path}')\n",
    "        ax[iteration, i].imshow(im)\n",
    "        if i > 0:\n",
    "            ax[iteration, i].text(\n",
    "                0.5, 0.5, f'Duplication',\n",
    "                horizontalalignment='center',\n",
    "                verticalalignment='center',\n",
    "                transform=ax[iteration, i].transAxes,\n",
    "                fontsize=12,\n",
    "                color='red',\n",
    "                weight='bold'\n",
    "            )\n",
    "        ax[iteration, i].set_title(path, fontsize=12)\n",
    "        ax[iteration, i].axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=-0.5, hspace=0.2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2. Dataset Overview\n",
    "\n",
    "Columns of focus: FileType, Ratio, Mode, Transparency, Animated, and Class."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "data_countplot(df_raw, 'FileType', ax=ax[0][0], title='File Types', annotate=True, palette='Set2')\n",
    "data_histplot(df_raw, 'Ratio', ax=ax[0][1], title='Image Ratio Density', bins=20, kde=True, stat='density')\n",
    "data_countplot(df_raw, 'Mode', ax=ax[0][2], title='Image Modes', annotate=True, palette='Accent')\n",
    "data_countplot(df_raw, 'Transparency', ax=ax[1][0], title='Transparency', annotate=True, palette='YlGn')\n",
    "data_countplot(df_raw, 'Animated', ax=ax[1][1], title='Animated', annotate=True, palette='YlGn')\n",
    "data_countplot(df_raw, 'Class', ax=ax[1][2], horizontal=True, title='Flower Classes', xticklabels_rotation=45, annotate=True, palette='Set1')\n",
    "\n",
    "fig.suptitle('Raw Dataset Statistics', fontsize=20, fontweight='bold', y=1.0)\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('images/EDA-RawDataset-Stats.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3. â˜ž Final Observation\n",
    "\n",
    "---\n",
    "\n",
    "### Duplicated Images:\n",
    "\n",
    "There are a lot of duplications in our dataset. We need to keep only one copy for each of these duplications.\n",
    "\n",
    "---\n",
    "\n",
    "### Dataset Overview:\n",
    "\n",
    "#### File Type:\n",
    "\n",
    "The majority of our raw dataset images are `.jpg` files (non-transparent). This will be our file format of choice that all other formats will be converted to:\n",
    "\n",
    "- `.jpeg`: These extensions can just be renamed to `.jpg`, since they are different extension standards for the same file format.\n",
    "- `.png`: Conversion for this format to `jpg` would be more involved, since this format might contain an alpha channel for transparency.\n",
    "\n",
    "\n",
    "#### Image Width, Height and Ratio:\n",
    "\n",
    "Our images are of various different width and height, and the most common ratio of our raw dataset images is 1:1 (1.0). During data processing, all images of ratio different from this will be cropped and resized to match a common 1:1 dimensions to enhance our models' performance.\n",
    "\n",
    "**Note:** Image ratio is calculated from an image's width divided by its height (see [`dataset.load()`](../utils/dataset.py) docs).\n",
    "\n",
    "#### Mode and Transparency:\n",
    "\n",
    "The majority of our raw dataset are non-transparent `RGB` images.\n",
    "\n",
    "There are also 18 non-transparent 8-bit grayscale pixels images (`L` mode). These images will not work with our Machine Learning models at all, since we are working with colored images. Since their number is insignificant, we can safely exclude them from our dataset during processing without making our dataset unbalanced.\n",
    "\n",
    "There are 323 images with transparency. Of these, there are 306 `RGBA` images. Thus, there must be 17 `P` images (8-bit colored pixels) with transparency, leaving us with 183 non-transparent `P` images. We will need to convert all of these into non-transparent `RGB` mode during data processing.\n",
    "\n",
    "\n",
    "#### Animated Images:\n",
    "\n",
    "We have no animated images in our dataset. No action needed.\n",
    "\n",
    "\n",
    "#### Class <span style=\"color:red\">(target column)</span>:\n",
    "\n",
    "Our raw dataset is already class balanced with roughly 2000 samples per class. No action needed to balance them.\n",
    "\n",
    "However, this column needs encoding for it to work with our Machine Learning models. We will use [Label Encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) for this column because:\n",
    "\n",
    "- We have 8 classes. Using one-hot encoding would create too many columns, slowing down our code.\n",
    "- We are dealing with Nominal categories (no inherent order)."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
