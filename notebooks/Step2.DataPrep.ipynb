{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2. Data Preparation\n",
    "\n",
    "---\n",
    "\n",
    "This step includes both data cleaning and data processing. The resulting data will be saved into `./data/processed/` folder under the same class-separated folder structure as the raw dataset. The steps are as follows:\n",
    "\n",
    "1. Remove Transparency and Grayscale: Convert images of all other modes to `RGB`, excluding `L` images (grayscale).\n",
    "2. Standardize Sizes and Aspect Ratios: **512x512** pixels, 1:1 aspect ratio.\n",
    "3. Remove Identical Images (Data Duplication). Method: Comparing `imagehash.average_hash()` of each image.\n",
    "4. Normalize Pixel Values: common scale: [0, 1].\n",
    "5. Quality Control: Manual inspection of a subset of images to ensure overall dataset quality."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports and environmental setups\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imagehash\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Custom utils functions\n",
    "from utils import dataset\n",
    "from utils.visualization import data_countplot\n",
    "from utils.visualization import data_histplot\n",
    "from utils.visualization import data_plot_16samples\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "path_raw_dataset = '../data/raw/'\n",
    "path_processed_dataset = '../data/processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Raw Dataset\n",
    "\n",
    "Using our custom `dataset.load()` function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_raw = dataset.load('../data/raw')\n",
    "df_raw.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "data_countplot(df_raw, 'FileType', ax=ax[0][0], title='File Types', annotate=True, palette='Set2')\n",
    "data_histplot(df_raw, 'Ratio', ax=ax[0][1], title='Image Ratio Density', bins=20, kde=True, stat='density')\n",
    "data_countplot(df_raw, 'Mode', ax=ax[0][2], title='Image Modes', annotate=True, palette='Accent')\n",
    "data_countplot(df_raw, 'Transparency', ax=ax[1][0], title='Transparency', annotate=True, palette='YlGn')\n",
    "data_countplot(df_raw, 'Animated', ax=ax[1][1], title='Animated', annotate=True, palette='YlGn')\n",
    "data_countplot(df_raw, 'Class', ax=ax[1][2], horizontal=True, title='Flower Classes', xticklabels_rotation=45, annotate=True, palette='Set1')\n",
    "\n",
    "fig.suptitle('Raw Dataset Statistics', fontsize=20, fontweight='bold', y=1.0)\n",
    "fig.tight_layout()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_plot_16samples(df_raw)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1. Data Cleaning and Processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.1. Duplicated Images Cleaning\n",
    "\n",
    "We are detecting all duplicated images and store them in a list `skipped_duplicated_images` (keeping the first copy) so that we can skip cleaning and processing and saving them into our processed dataset in `../data/processed/`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_hashes = {}\n",
    "for i, row in df_raw.iterrows():\n",
    "    with Image.open(f'../data/raw/{row[\"ImgPath\"]}') as im:\n",
    "        image_hash = imagehash.average_hash(im, hash_size=8)\n",
    "        if image_hash in image_hashes:\n",
    "            image_hashes[image_hash].append(row[\"ImgPath\"])\n",
    "        else:\n",
    "            image_hashes[image_hash] = [row[\"ImgPath\"]]\n",
    "\n",
    "duplicated_image_hashes = {hash_val: paths for hash_val, paths in image_hashes.items() if len(paths) > 1}  # Remove hashes with a single path\n",
    "\n",
    "skipped_duplicated_images = []\n",
    "for paths in duplicated_image_hashes.values():\n",
    "    for i, path in enumerate(paths):\n",
    "        if i > 0:  # Keeping the first copy\n",
    "            skipped_duplicated_images.append(path)\n",
    "\n",
    "print(f'Number of skipped duplicated images: {len(skipped_duplicated_images)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.3. Further Cleaning and Processing\n",
    "\n",
    "- Remove Transparency and Grayscale\n",
    "- Standardize Sizes and Aspect Ratios\n",
    "- Normalize Pixel Values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "COMMON_DIM = 512  # Target common dimension (width and height for all processed images)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_transparency(image: Image) -> Image:\n",
    "    if im.mode in ('RGBA', 'RGBa', 'LA', 'La', 'PA', 'P'):\n",
    "        if image.mode != 'RGBA':\n",
    "            image = image.convert('RGBA')\n",
    "        image = image.convert('RGB')\n",
    "    return image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def resize_crop(image: Image, width: int, height: int) -> Image:\n",
    "    original_ratio = image.width / image.height\n",
    "\n",
    "    # Determine the target dimensions\n",
    "    if original_ratio > width / height:\n",
    "        target_width = width\n",
    "        target_height = int(width / original_ratio)\n",
    "    else:\n",
    "        target_width = int(height * original_ratio)\n",
    "        target_height = height\n",
    "    image = image.resize((target_width, target_height))  # Resize to target dimensions\n",
    "\n",
    "    # Centered crop\n",
    "    left = (target_width - width) // 2\n",
    "    top = (target_height - height) // 2\n",
    "    right = left + width\n",
    "    bottom = top + height\n",
    "    image = image.crop((left, top, right, bottom))\n",
    "\n",
    "    return image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def normalize_pixels(image: Image) -> Image:\n",
    "    image_array = np.array(image)\n",
    "    normalized_image_array = image_array / 255.0  # Normalize pixel values to the range [0, 1]\n",
    "    return Image.fromarray((normalized_image_array * 255).astype(np.uint8))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, row in df_raw.iterrows():\n",
    "    if not os.path.exists(f'{path_processed_dataset}{row[\"Class\"]}'):\n",
    "        os.makedirs(f'{path_processed_dataset}{row[\"Class\"]}')\n",
    "\n",
    "    img_path = row['ImgPath']\n",
    "    if img_path in skipped_duplicated_images:\n",
    "        continue\n",
    "\n",
    "    new_img_path = ''.join(img_path.split('.')[0:-1]) + '.jpg'\n",
    "    with Image.open(f'{path_raw_dataset}{img_path}') as im:\n",
    "        if im.mode == 'L':\n",
    "            continue  # Ignoring grayscale images\n",
    "\n",
    "        im = remove_transparency(im)\n",
    "        im = resize_crop(im, COMMON_DIM, COMMON_DIM)\n",
    "\n",
    "        im.save(f'{path_processed_dataset}{new_img_path}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2. Quality Control"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_processed = dataset.load('../data/processed')\n",
    "df_processed.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "data_countplot(df_processed, 'FileType', ax=ax[0][0], title='File Types', annotate=True, palette='Set2')\n",
    "data_countplot(df_processed, 'Ratio', ax=ax[0][1], title='Image Ratio', annotate=True)\n",
    "data_countplot(df_processed, 'Mode', ax=ax[0][2], title='Image Modes', annotate=True, palette='Accent')\n",
    "data_countplot(df_processed, 'Transparency', ax=ax[1][0], title='Transparency', annotate=True, palette='YlGn')\n",
    "data_countplot(df_processed, 'Animated', ax=ax[1][1], title='Animated', annotate=True, palette='YlGn')\n",
    "data_countplot(df_processed, 'Class', ax=ax[1][2], horizontal=True, title='Flower Classes', xticklabels_rotation=45, annotate=True, palette='Set1')\n",
    "\n",
    "fig.suptitle('Processed Dataset Statistics', fontsize=20, fontweight='bold', y=1.0)\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('images/DataPrep-ProcessedDataset-Stats.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_plot_16samples(df_processed, to_file='images/DataPrep-ProcessedDataset-16Samples.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
