{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Flower Classifier - Convolutional Neural Network\n",
    "\n",
    "This approach is better suited than pure Artificial Neural Network (ANN) because it is able to reliably capture important features in a 2D image.\n",
    "\n",
    "Optimizer: `tf.keras.optimizers.RMSprop`\n",
    "\n",
    "According to [Tensorflow API docs](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental/RMSprop), The gist of RMSprop is to:\n",
    "\n",
    "- Maintain a moving (discounted) average of the square of gradients\n",
    "- Divide the gradient by the root of this average\n",
    "\n",
    "Thus, this is a good choice for non-stationery problems. From observing our baseline ANN model that uses Adam optimizer and its prediction on the test dataset, we saw that the baseline model struggles to capture our non-stationary data: there is significant variance in lighting, angle, zoom level, etc. As such, RMSprop is a better choice than Adam.\n",
    "\n",
    "Since our data is balanced, the metric we are using to evaluate its performance is **Accuracy** ($Accuracy = \\frac{correct \\; classifications}{all \\; classifications}$), more specifically its [Tensorflow's CategoricalAccuracy Implementation](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/CategoricalAccuracy).\n",
    "\n",
    "Refer to the code below to see how it is set up, trained, and evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports and environmental setups\n",
    "\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "# Custom utils functions\n",
    "from utils import dataset\n",
    "from utils.visualization import plot_learning_curve\n",
    "from utils.visualization import visualize_16predictions\n",
    "from utils.glob import TARGET_IMG_SIZE\n",
    "\n",
    "\n",
    "# Reproducible results\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Misc.\n",
    "plt.style.use('ggplot')\n",
    "model_name = 'clf-cnn'\n",
    "dir_raw_dataset = '../data/raw/'\n",
    "dir_train_dataset = '../data/train/'\n",
    "dir_test_dataset = '../data/test/'\n",
    "dir_log = '../log/' + model_name\n",
    "dir_models = '../models/'\n",
    "path_model = dir_models + model_name\n",
    "\n",
    "\n",
    "# Environment information\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.load(dir_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(n=42, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(df, shuffle=True, test_size=0.25, random_state=42)  # 80/20/20 - train/val/test\n",
    "\n",
    "print(f'Train data: {train.shape[0]} samples, Validation Data: {val.shape[0]} samples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Model Setup and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "BATCH_SIZE = 512\n",
    "INPUT_DIM = (TARGET_IMG_SIZE, TARGET_IMG_SIZE, 3)  # RGB - 3 channels images\n",
    "OUTPUT_CLASSES = 8  # One-hot encoded: 8 different classes\n",
    "\n",
    "# Training Parameters\n",
    "EPOCHS = 32\n",
    "LEARNING_RATE = 1e-2\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=INPUT_DIM)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(4, (4, 4), activation='relu')(inputs)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(8, (4, 4), activation='relu')(x)\n",
    "x = tf.keras.layers.Attention()(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(8, (1, 1), activation='sigmoid', padding='same')(x),\n",
    "        x\n",
    "    ],\n",
    ")\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(16, (4, 4), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(32, (4, 4), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(64, (4, 4), activation='relu')(x)\n",
    "x = tf.keras.layers.GlobalMaxPool2D()(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x, training=True)\n",
    "\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x, training=True)\n",
    "\n",
    "x = tf.keras.layers.Dense(128, activation='sigmoid')(x)\n",
    "outputs = tf.keras.layers.Dense(OUTPUT_CLASSES)(x)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name=model_name)\n",
    "model.compile(\n",
    "    optimizer=RMSprop(learning_rate=LEARNING_RATE, momentum=MOMENTUM),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['categorical_accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, to_file=f'images/{model_name}-Diagram.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Class'] = train['Class'].astype('str')\n",
    "train_datagen = ImageDataGenerator(data_format='channels_last')\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    directory=dir_train_dataset,\n",
    "    x_col='ImgPath',\n",
    "    y_col='Class',\n",
    "    target_size=(TARGET_IMG_SIZE, TARGET_IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val['Class'] = val['Class'].astype('str')\n",
    "val_datagen = ImageDataGenerator(data_format='channels_last')\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val,\n",
    "    directory=dir_train_dataset,\n",
    "    x_col='ImgPath',\n",
    "    y_col='Class',\n",
    "    target_size=(TARGET_IMG_SIZE, TARGET_IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=dir_log, write_graph=False)\n",
    "history = model.fit(\n",
    "    train_generator, validation_data=val_generator,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=train.shape[0] // BATCH_SIZE,\n",
    "    validation_steps=val.shape[0] // BATCH_SIZE,\n",
    "    verbose=1, callbacks=[tensorboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(\n",
    "    history.history['loss'],\n",
    "    history.history['val_loss'],\n",
    "    history.history['categorical_accuracy'],\n",
    "    history.history['val_categorical_accuracy'],\n",
    "    to_file=f'images/{model_name}-LearningCurve.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Model Performance\n",
    "\n",
    "Evaluated against test dataset in `./data/test/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dataset.load(dir_test_dataset)\n",
    "test['Class'] = test['Class'].astype('str')\n",
    "test_datagen = ImageDataGenerator(data_format='channels_last')\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test,\n",
    "    directory=dir_test_dataset,\n",
    "    x_col='ImgPath',\n",
    "    y_col='Class',\n",
    "    target_size=(TARGET_IMG_SIZE, TARGET_IMG_SIZE),\n",
    "    batch_size=1,\n",
    "    class_mode='categorical',\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_16predictions(model, test_generator, to_file=f'images/{model_name}-16SamplePredictions.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**â˜ž Observation**\n",
    "\n",
    "We can see that this CNN model has significantly higher performance **(around <span style=\"color:red\">0.7</span> accuracy)** comparing to our baseline ANN model (0.5). By using convolutional layers, our model is now better at capturing most of the important features in our training data while being resistant to noise.\n",
    "\n",
    "**This will be our final model.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Model Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(path_model, overwrite = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
